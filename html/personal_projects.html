<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Personal Projects - Josh Aney</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>

<script src="../js/slideshow.js"></script>

<header>
    <nav>
        <ul>
            <li><a href="index.html">About Me</a></li>
            <li><a href="research_experience.html">Research/Experience</a></li>
            <li><a href="personal_projects.html">Personal Projects</a></li>
            <li><a href="../images/resume.pdf" target="_blank">Resume</a></li>
        </ul>
    </nav>
</header>

<main>

    <h1>Personal Projects</h1>
    <p>This page is meant to give a short descriptions of many of the projects that I have been a part of. </p>

    <p>There are four machine learning projects that are listed. These projects are set up in an experiment style where
    a question was prompted and then an experiment was completed to test our hypotheses. A full report will be linked
    after each project. This report will contain a detailed explanation of the problem, the methods that were used in the
    experiment, and a detailed analysis of the results</p>

    <p>The next project is a small web application that is meant to help a user track what trails they have ridden in
    the Bozeman area. This application lets users add trails which the trails will then be plotted on a 3d map as well
    as being displayed on the home page. </p>

    <p>The final project is a small unity game that allows the user to rol a ball around a surface while trying to
        collect  pick-ups. There is a antagonist that will chase the user while they are trying to pick up the
        collectibles.</p>

    <p>All the source code for these projects can be found on my <a href="https://github.com/joshaney324">GitHub</a>.</p>

    <div class="project-list">
        <ul>
            <li><strong>Project 1: </strong><a href="#ml_1">Naive Bayes Model From Scratch</a></li>
            <li><strong>Project 2: </strong><a href="#ml_2">K-Nearest-Neighbors Methods From Scratch</a></li>
            <li><strong>Project 3: </strong><a href="#ml_3">Neural Network From Scratch</a></li>
            <li><strong>Project 4: </strong><a href="#ml_4">Experimenting With Different Neural Network Training Methods (Backpropagation and Population Based Methods)</a></li>
            <li><strong>Project 5: </strong><a href="#bike-webapp">Bozeman Bike Trails Web Application</a></li>
            <li><strong>Project 6: </strong><a href="#unity">Unity Project</a></li>
        </ul>
    </div>

    <div id="ml_1" class="container">
        <section class="project">
            <h2>Machine Learning Project 1 - Naive Bayes</h2>
            <p><strong>Description:</strong> For this project, I worked in a team with another student at Montana State University. We
                were faced with coding a Naive Bayes model from scratch to be used on classification datasets from the
                <a href="https://archive.ics.uci.edu/">UCI Machine Learning Repository</a>. For this project, we used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/105/congressional+voting+records">Congressional Voting Records Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/53/iris">Iris Dataset</a>, and
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>. Once we had
                a base metric for our model, we inserted a simulated noise by randomizing one of the features of each dataset.
                We then Compared our results from the noisy and non-noisy data. All of this was done in python.</p>
            <p><strong>Results:</strong> Our Naive Bayes model performed well on all the datasets with a slight decrease in performance with the simulated noise.</p>


            <div class="slideshow-container ml_1">

                <div class="mySlides fade" data-caption="Original Data Averages">
                    <img src="../images/ml_1/original_data_avgs.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Noisy Data Averages">
                    <img src="../images/ml_1/noisy_data_avgs.svg" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_1', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_1', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>
            <br>

            <p>The full results from this experiment can be found <a href="../images/ml_1/ml_paper_1.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="ml_2" class="container">
        <section class="project">
            <h2>Machine Learning Project 2 - K Nearest Neighbors Methods</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding a KNN classification model, KNN regression model, edited KNN classification
                model, edited KNN regression model, and a K-Means clustering model from scratch. We then used these
                models on a variety of datasets. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                An experiment was then conducted to compare each of these models. This was all done in python.</p>
            <p><strong>Results</strong>: Many of the K Nearest Neighbors Methods performed better on classification data then on regression data.
                The performance of individual models depended on the structure of each dataset.</p>


            <div class="slideshow-container ml_2">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_2/BreastCancerBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_2/SoyBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_2/GlassBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_2/AbaloneBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_2/HardwareBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_2/ForestBarPlot.png" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_2', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_2', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>
            <br>

            <p>The full results from this experiment can be found <a href="../images/ml_2/ml_paper_2.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="ml_3" class="container">
        <section class="project">
            <h2>Machine Learning Project 3 - Densely Connected Neural Network</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding a densely connected neural network. This network was trained with backpropagation. We then used our
                model on a variety of datasets. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                An experiment was then conducted to analyze the performance of our neural network with varying network
                sizes and varying amounts of hidden layers on each dataset.</p>
            <p><strong>Results</strong>: The neural network tended to perform better with zero or one hidden layer,
                compared to two hidden layers. The amount of nodes in each hidden layer varied depending on the results
                from hyperparameter tuning.</p>

            <div class="slideshow-container ml_3">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_3/breast_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_3/soy_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_3/glass_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_3/abalone_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_3/machine_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_3/forest_bar.svg" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_3', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_3', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>

            <p>The full results from this experiment can be found <a href="../images/ml_3/ml_paper_3.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="ml_4" class="container">
        <section class="project">
            <h2>Machine Learning Project 4 - A Comparison of Neural Network Training Methods</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding multiple different training methods for a neural network. We focussed on
                population based methods and backpropogation. We then used our
                models on a variety of datasets. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                This project then built on project 3. We compared our results from backpropogation to three other
                network training algorithms. These algorithms were the genetic algorithm, differential evolution, and
                particle swarm optimization.</p>
            <p><strong>Results</strong>: The performance of the models was really variable. Datasets that tended to
                overfit with backpropogation would often perform better with population based methods.</p>
            <div class="slideshow-container ml_4">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_4/BreastCancerAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_4/SoyAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_4/GlassAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_4/AbaloneMSE.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_4/MachineMSE.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_4/ForestMSE.png" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_4', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_4', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>

            <p>The full results from this experiment can be found <a href="../images/ml_4/ml_paper_4.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="bike-webapp" class="container">
        <section class="project">
            <h2>Web Project</h2>
            <p>Description: A short description of your web project, the goal of the website, and the technologies you used (e.g., HTML, CSS, JavaScript, etc.).</p>
            <p>Technologies: List the web development tools used (e.g., React, Node.js, etc.).</p>
            <p>Results: Any key features or achievements of the web project, such as user interactions or functionality.</p>
        </section>
    </div>

    <div id="unity" class="container">
        <section class="project">
            <h2>Unity Project</h2>
            <p>Description: A brief explanation of the Unity game or application project.</p>
            <p>Technologies: Mention the Unity version and other tools you used for development.</p>
            <p>Results: Any significant outcomes or experiences from the Unity project.</p>
        </section>
    </div>

</main>

</body>
</html>
