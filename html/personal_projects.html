<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Personal Projects - Josh Aney</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>

<script src="../js/slideshow.js"></script>

<header>
    <nav>
        <ul>
            <li><a href="index.html">About Me</a></li>
            <li><a href="research_experience.html">Research/Experience</a></li>
            <li><a href="personal_projects.html">Personal Projects</a></li>
            <li><a href="../images/resume.pdf" target="_blank">Resume</a></li>
        </ul>
    </nav>
</header>

<main>

    <h1>Personal Projects</h1>
    <p>This page is meant to give a short descriptions of many of the projects that I have been a part of. </p>

    <p>There are four machine learning projects that are listed. These projects are set up in an experiment style where
    a question was prompted and then an experiment was completed to test our hypotheses. A full report will be linked
    after each project. This report will contain a detailed explanation of the problem, the methods that were used in the
    experiment, and a detailed analysis of the results</p>

    <p>The next project is a small web application that is meant to help a user track what trails they have ridden in
    the Bozeman area. This application lets users add trails which the trails will then be plotted on a 3d map as well
    as being displayed on the home page. </p>

    <p>The final project is a small unity game that allows the user to rol a ball around a surface while trying to
        collect  pick-ups. There is a antagonist that will chase the user while they are trying to pick up the
        collectibles.</p>

    <p>All the source code for these projects can be found on my <a href="https://github.com/joshaney324">GitHub</a>.</p>

    <div class="project-list">
        <ul>
            <li><strong>Project 1: </strong><a href="#ml_1">Naive Bayes Model From Scratch</a></li>
            <li><strong>Project 2: </strong><a href="#ml_2">K-Nearest-Neighbors Methods From Scratch</a></li>
            <li><strong>Project 3: </strong><a href="#ml_3">Neural Network From Scratch</a></li>
            <li><strong>Project 4: </strong><a href="#ml_4">Experimenting With Different Neural Network Training Methods (Backpropagation and Population Based Methods)</a></li>
            <li><strong>Project 5: </strong><a href="#bike-webapp">Bozeman Bike Trails Web Application</a></li>
            <li><strong>Project 6: </strong><a href="#unity">Unity Project</a></li>
        </ul>
    </div>

    <div id="ml_1" class="container">
        <section class="project">
            <h2>Machine Learning Project 1 - Naive Bayes</h2>
            <p><strong>Description:</strong> For this project, I worked in a team with another student at Montana State University. We
                were faced with coding a Naive Bayes model from scratch to be used on classification datasets from the
                <a href="https://archive.ics.uci.edu/">UCI Machine Learning Repository</a>. For this project, we used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/105/congressional+voting+records">Congressional Voting Records Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/53/iris">Iris Dataset</a>, and
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>. A base model
                performance was received after testing each of the datasets. We performed 10-fold cross validation, and
                we used precision recall and accuracy as the metrics. Once we had a base performance, we then added
                artificial noise to the datasets. This was done by selecting one feature in the dataset at random and
                then mixing up the order of that given attribute. We then performed the experiment one more time to test
                how our Naive Bayes model performed with more noise.</p>
            <p><strong>Results:</strong> Our Naive Bayes model performed well on all the datasets with a slight decrease in performance with the simulated noise.</p>


            <div class="slideshow-container ml_1">

                <div class="mySlides fade" data-caption="Original Data Averages">
                    <img src="../images/ml_1/original_data_avgs.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Noisy Data Averages">
                    <img src="../images/ml_1/noisy_data_avgs.svg" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_1', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_1', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>
            <br>

            <p>The full results from this experiment can be found <a href="../images/ml_1/ml_paper_1.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="ml_2" class="container">
        <section class="project">
            <h2>Machine Learning Project 2 - K Nearest Neighbors Methods</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding a KNN classification model, KNN regression model, edited KNN classification
                model, edited KNN regression model, and a K-Means clustering model from scratch. We then used these
                models on a variety of datasets. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                For the classification datasets, a base KNN classification model was created. To do this we took out a
                hold-out fold from the data to tune all the hyperparameters for the model. Once the model was tuned, 10-fold
                cross validation was completed with the remaining data. There was no removal of noisy data during this run.
                We then completed another run of this experiment, but we used an edited KNN classification model, so the
                model would remove data points that it got wrong. This in turn ended up removing noise. A similar process
                was completed for the regression datasets, but the only difference in the model was that a kernel was
                used to weight the distance of the K closest neighbors instead of just going with the mean of the k
                closest neighbors. For the edited KNN regression model, we had to tune a threshold for how close the
                prediction was to the actual value to decide if the model would remove the datapoint. Finally, we
                performed the experiment one more time, but instead of using edited KNN models to find the edited dataset,
                we used the centroids from a K-Means Clustering model. Once these experiments were completed, we then
                analyzed and compared the results from all the different models</p>
            <p><strong>Results</strong>: Many of the K Nearest Neighbors Methods performed better on classification data then on regression data.
                The performance of individual models depended on the structure of each dataset. Depending on if the dataset
                contained large amounts of outliers, the K-Means model or the edited model would perform better.</p>


            <div class="slideshow-container ml_2">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_2/BreastCancerBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_2/SoyBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_2/GlassBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_2/AbaloneBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_2/HardwareBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_2/ForestBarPlot.png" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_2', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_2', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>
            <br>

            <p>The full results from this experiment can be found <a href="../images/ml_2/ml_paper_2.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="ml_3" class="container">
        <section class="project">
            <h2>Machine Learning Project 3 - Densely Connected Neural Network</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding a densely connected neural network. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                The network that was created to be used on this data was a densely connected network with no bias nodes.
                Standard backpropagation was then used to train the network based off of the loss functions that we
                designated each dataset. Once this was done, we tuned learning rate, and the number of nodes in each
                hidden layer for zero, one and two hidden layers based off of each dataset. The tuning was done in the
                same manner as it was done in the KNN methods project with a hold-out fold. An experiment was then conducted to analyze the performance of our neural network with varying network
                sizes and varying amounts of hidden layers on each dataset. Each dataset was tested by completing 10-fold
                cross validation excluding the hold out fold's data points. These results were then analyzed for each dataset.</p>
            <p><strong>Results</strong>: The neural network tended to perform better with zero or one hidden layer,
                compared to two hidden layers. On the more complex datasets, the network may perform better with one
                hidden layer, but it rarely performed best with two hidden layers.</p>

            <div class="slideshow-container ml_3">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_3/breast_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_3/soy_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_3/glass_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_3/abalone_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_3/machine_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_3/forest_bar.svg" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_3', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_3', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>

            <p>The full results from this experiment can be found <a href="../images/ml_3/ml_paper_3.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="ml_4" class="container">
        <section class="project">
            <h2>Machine Learning Project 4 - A Comparison of Neural Network Training Methods</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding multiple different training methods for a neural network. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                This project then built on project 3. We used the same network structure that was created in project 3,
                but this time we intended on testing other training methods. We used backpropagation as our baseline to
                compare to, then we trained the network by the genetic algorithm, differential evolution, and particle
                swarm optimization. Because of the complexity of these algorithms and the computational power needed,
                we only tuned a small amount of the available hyperparameters. Once again we performed 10-fold cross
                validation on all the datasets and then compared the results across all the training methods.</p>
            <p><strong>Results</strong>: The performance of the models was really variable. Datasets that tended to
                overfit with backpropagation would often perform better with population based methods and datasets that
                were relatively simple would often perform drastically better with backpropagation.</p>
            <div class="slideshow-container ml_4">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_4/BreastCancerAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_4/SoyAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_4/GlassAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_4/AbaloneMSE.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_4/MachineMSE.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_4/ForestMSE.png" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_4', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_4', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>

            <p>The full results from this experiment can be found <a href="../images/ml_4/ml_paper_4.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div id="bike-webapp" class="container">
        <section class="project">
            <h2>Web Project</h2>
            <p>Description: A short description of your web project, the goal of the website, and the technologies you used (e.g., HTML, CSS, JavaScript, etc.).</p>
            <p>Technologies: List the web development tools used (e.g., React, Node.js, etc.).</p>
            <p>Results: Any key features or achievements of the web project, such as user interactions or functionality.</p>
        </section>
    </div>

    <div id="unity" class="container">
        <section class="project">
            <h2>Unity Project</h2>
            <p>Description: A brief explanation of the Unity game or application project.</p>
            <p>Technologies: Mention the Unity version and other tools you used for development.</p>
            <p>Results: Any significant outcomes or experiences from the Unity project.</p>
        </section>
    </div>

</main>

</body>
</html>
