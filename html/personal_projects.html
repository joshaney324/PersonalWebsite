<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Personal Projects - Josh Aney</title>
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>

<script src="../js/slideshow.js"></script>

<header>
    <nav>
        <ul>
            <li><a href="index.html">About Me</a></li>
            <li><a href="research_experience.html">Research/Experience</a></li>
            <li><a href="personal_projects.html">Personal Projects</a></li>
            <li><a href="../images/resume.pdf" target="_blank">Resume</a></li>
        </ul>
    </nav>
</header>

<main>
    <div class="container">
        <section class="project">
            <h2>Machine Learning Project 1 - Naive Bayes</h2>
            <p><strong>Description:</strong> For this project, I worked in a team with another student at Montana State University. We
                were faced with coding a Naive Bayes model from scratch to be used on classification datasets from the
                <a href="https://archive.ics.uci.edu/">UCI Machine Learning Repository</a>. For this project, we used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/105/congressional+voting+records">Congressional Voting Records Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/53/iris">Iris Dataset</a>, and
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>. Once we had
                a base metric for our model, we inserted a simulated noise by randomizing one of the features of each dataset.
                We then Compared our results from the noisy and non-noisy data. All of this was done in python.</p>
            <p><strong>Results:</strong> Our Naive Bayes model performed well on all the datasets with a slight decrease in performance with the simulated noise.</p>


            <div class="slideshow-container ml_1">

                <div class="mySlides fade" data-caption="Original Data Averages">
                    <img src="../images/ml_1/original_data_avgs.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Noisy Data Averages">
                    <img src="../images/ml_1/noisy_data_avgs.svg" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_1', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_1', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>
            <br>

            <p>The full results from this experiment can be found <a href="../images/ml_1/ml_paper_1.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div class="container">
        <section class="project">
            <h2>Machine Learning Project 2 - K Nearest Neighbors Methods</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding a KNN classification model, KNN regression model, edited KNN classification
                model, edited KNN regression model, and a K-Means clustering model from scratch. We then used these
                models on a variety of datasets. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                An experiment was then conducted to compare each of these models. This was all done in python.</p>
            <p><strong>Results</strong>: Many of the K Nearest Neighbors Methods performed better on classification data then on regression data.
                The performance of individual models depended on the structure of each dataset.</p>


            <div class="slideshow-container ml_2">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_2/BreastCancerBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_2/SoyBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_2/GlassBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_2/AbaloneBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_2/HardwareBarPlot.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_2/ForestBarPlot.png" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_2', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_2', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>
            <br>

            <p>The full results from this experiment can be found <a href="../images/ml_2/ml_paper_2.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div class="container">
        <section class="project">
            <h2>Machine Learning Project 3 - Densely Connected Neural Network</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding a densely connected neural network. This network was trained with backpropagation. We then used our
                model on a variety of datasets. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                An experiment was then conducted to analyze the performance of our neural network with varying network
                sizes and varying amounts of hidden layers on each dataset.</p>
            <p><strong>Results</strong>: The neural network tended to perform better with zero or one hidden layer,
                compared to two hidden layers. The amount of nodes in each hidden layer varied depending on the results
                from hyperparameter tuning.</p>

            <div class="slideshow-container ml_3">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_3/breast_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_3/soy_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_3/glass_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_3/abalone_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_3/machine_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_3/forest_bar.svg" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_3', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_3', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>

            <p>The full results from this experiment can be found <a href="../images/ml_3/ml_paper_3.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div class="container">
        <section class="project">
            <h2>Machine Learning Project 4 - A Comparison of Neural Network Training Methods</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana State University.
                We were tasked with coding multiple different training methods for a neural network. We focussed on
                population based methods and backpropogation. We then used our
                models on a variety of datasets. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                This project then built on project 3. We compared our results from backpropogation to three other
                network training algorithms. These algorithms were the genetic algorithm, differential evolution, and
                particle swarm optimization.</p>
            <p><strong>Results</strong>: The performance of the models was really variable. Datasets that tended to
                overfit with backpropogation would often perform better with population based methods.</p>
            <div class="slideshow-container ml_4">

                <div class="mySlides fade" data-caption="Breast Cancer Dataset Performance">
                    <img src="../images/ml_4/BreastCancerAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Soybean (small) Dataset Performance">
                    <img src="../images/ml_4/SoyAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Glass Dataset Performance">
                    <img src="../images/ml_4/GlassAccuracy.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Abalone Dataset Performance">
                    <img src="../images/ml_4/AbaloneMSE.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Computer Hardware Dataset Performance">
                    <img src="../images/ml_4/MachineMSE.png" class="slideshow-img">
                </div>

                <div class="mySlides fade" data-caption="Forest Fire Dataset Performance">
                    <img src="../images/ml_4/ForestMSE.png" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_4', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_4', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>

            <p>The full results from this experiment can be found <a href="../images/ml_4/ml_paper_4.pdf" target="_blank">here</a></p>
        </section>
    </div>

    <div class="container">
        <section class="project">
            <h2>Web Project</h2>
            <p>Description: A short description of your web project, the goal of the website, and the technologies you used (e.g., HTML, CSS, JavaScript, etc.).</p>
            <p>Technologies: List the web development tools used (e.g., React, Node.js, etc.).</p>
            <p>Results: Any key features or achievements of the web project, such as user interactions or functionality.</p>
        </section>
    </div>

    <div class="container">
        <section class="project">
            <h2>Unity Project</h2>
            <p>Description: A brief explanation of the Unity game or application project.</p>
            <p>Technologies: Mention the Unity version and other tools you used for development.</p>
            <p>Results: Any significant outcomes or experiences from the Unity project.</p>
        </section>
    </div>

</main>

</body>
</html>
