<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Densely Connected Neural Network From Scratch - Josh Aney</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <link rel="stylesheet" href="css/style.css">
</head>

<body>

<script src="js/slideshow.js"></script>

<header>
    <nav>
        <ul>
            <li><a href="index.html">About Me</a></li>
            <li><a href="personal_projects.html">Personal Projects</a></li>
            <li><a href="images/resume.pdf" target="_blank">Resume</a></li>
        </ul>
    </nav>
</header>

<main>

    <div id="ml_3" class="container">
        <section class="project">
            <h2>Machine Learning Project 3 - Densely Connected Neural Network</h2>
            <p><strong>Description</strong>: For this project, I worked in a team with two other students at Montana
                State University.
                We were tasked with coding a densely connected neural network. We used the
                <a href="https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original">Breast Cancer
                    Wisconsin Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/42/glass+identification">Glass Identification Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/91/soybean+small">Soybean (Small) Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/1/abalone">Abalone Dataset</a>,
                <a href="https://archive.ics.uci.edu/dataset/162/forest+fires">Forest Fires Dataset</a>, and the
                <a href="https://archive.ics.uci.edu/dataset/29/computer+hardware">Computer Hardware Dataset</a>.
                The network that was created to be used on this data was a densely connected network with no bias nodes.
                Standard backpropagation was then used to train the network based off of the loss functions that we
                designated each dataset. Once this was done, we tuned learning rate, and the number of nodes in each
                hidden layer for zero, one and two hidden layers based off of each dataset. The tuning was done in the
                same manner as it was done in the KNN methods project with a hold-out fold. An experiment was then
                conducted to analyze the performance of our neural network with varying network
                sizes and varying amounts of hidden layers on each dataset. Each dataset was tested by completing
                10-fold
                cross validation excluding the hold out fold's data points. These results were then analyzed for each
                dataset.</p>
            <br>
            <!--            <p>The full design document for this project can be found <a href="images/ml_3/Project%203%20Design%20Document.pdf" target="_blank">here</a>.</p>-->
            <!--            <br>-->
            <p><strong>Results</strong>: The neural network tended to perform better with zero or one hidden layer,
                compared to two hidden layers. On the more complex datasets, the network may perform better with one
                hidden layer, but it rarely performed best with two hidden layers.</p>

            <div class="slideshow-container ml_3">

                <div class="mySlides fade-slide" data-caption="Breast Cancer Dataset Performance">
                    <img src="images/ml_3/breast_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade-slide" data-caption="Soybean (small) Dataset Performance">
                    <img src="images/ml_3/soy_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade-slide" data-caption="Glass Dataset Performance">
                    <img src="images/ml_3/glass_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade-slide" data-caption="Abalone Dataset Performance">
                    <img src="images/ml_3/abalone_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade-slide" data-caption="Computer Hardware Dataset Performance">
                    <img src="images/ml_3/machine_bar.svg" class="slideshow-img">
                </div>

                <div class="mySlides fade-slide" data-caption="Forest Fire Dataset Performance">
                    <img src="images/ml_3/forest_bar.svg" class="slideshow-img">
                </div>

                <div style="padding-top: 20px">
                    <a class="prev" onclick="showSlide('.ml_3', -1)">&#10094;</a>
                    <a class="next" onclick="showSlide('.ml_3', 1)">&#10095;</a>
                    <span class="caption"></span>
                </div>

            </div>

            <br>

            <p><strong>Technologies</strong>: Python, Numpy, Matplotlib, UML, Latex</p>

            <br>
            <p><strong>Note</strong>: If you would like to see the full design document, code base, and research paper that goes with this project please feel free to reach out to me by email.</p>

            <br>
            <div class="text-center mt-5 mb-4">
                <a href="personal_projects.html" class="btn btn-primary">
                    ← Back to Personal Projects
                </a>
            </div>
            <!--            <p>The full results from this experiment can be found <a href="images/ml_3/ml_paper_3.pdf" target="_blank">here</a></p>-->
        </section>
    </div>

</main>

<footer class="footer">
    <div class="footer-bottom">
        <p>© 2024 Josh Aney | <a href="mailto:josh.aney@icloud.com">josh.aney@icloud.com</a> | <a
                href="tel:+5075130517">(507)-513-0517</a> | GitHub: <a
                href="https://github.com/joshaney324">joshaney324</a></p>
    </div>
</footer>

</body>


</html>